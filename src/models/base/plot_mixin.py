import logging

from typing import Union, List

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

from pathlib import WindowsPath
from pandas import DataFrame, Series
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

logger = logging.getLogger(__name__)

plt.style.use("seaborn")


def save_or_show_plot(plot_save_path: Union[str, WindowsPath] = None) -> None:
    """
    A helper function to either save or show the plots generated by functions.

    :param plot_save_path: a string or WindowsPath from pathlib to the path to save the plots to
    with the plot name included. Leave as None, if only showing of plots and no saving is desired.
    """
    if "None" in plot_save_path:
        plt.show()
    else:
        plt.savefig(plot_save_path)
        plt.close()


class PlotsMixin:
    """
    Mixin class for plotting data

    """

    @staticmethod
    def plot_reduced_timeseries(
        df_with_anomaly_indicator: DataFrame,
        pca_n_components: int = 0,
        cols_to_display: List[str] = None,
    ):
        """
        Function that takes as input a dataframe with timeseries data, where an anomaly indicator column is present
        and represents the level of 'anomaliness' for each datapoint, and reduces the dimensions by PCA for easier
        visualization of the whole dataset

        :param df_with_anomaly_indicator: the dataframe with data to be plotted and reduced. MUST have a column whose
               name contains 'anomaly'. This column can be binary or float.
        :type  df_with_anomaly_indicator: DataFrame
        :param pca_n_components: number of principal components (PC's) to reduce the original P columns of the data to
        :type  pca_n_components: int, default=0
        :param cols_to_display: an optional list of column names from the dataset to display in the plot with the PC's
        :type  cols_to_display: List[str], default=None
        """

        anomaly_column = df_with_anomaly_indicator.columns.str.contains("anomaly_count")
        df_features = df_with_anomaly_indicator.loc[:, ~anomaly_column]
        if cols_to_display is None:
            max_features_to_display = np.max(
                [np.min([df_features.shape[1], 3]) - pca_n_components, 1]
            )
            cols_to_display = df_features.columns[0:max_features_to_display]
            df_reduced = pd.DataFrame(df_features[cols_to_display])
        else:
            df_reduced = df_features[cols_to_display]

        if pca_n_components > 0:
            scaler = StandardScaler()
            df_features_scaled = scaler.fit_transform(df_features)

            pca = PCA(n_components=pca_n_components)
            pca_components = pca.fit_transform(df_features_scaled).reshape(df_features.shape[0], -1)
            pca_col_names = ["PC{}".format(pc) for pc in np.arange(1, pca_components.shape[1] + 1)]
            df_pca = pd.DataFrame(pca_components, columns=pca_col_names, index=df_reduced.index)
            df_reduced = pd.concat([df_reduced, df_pca], axis=1)
            pca_explained_var = 100 * pca.explained_variance_ratio_.sum()
            plot_title = (
                f"Features with sum of model anomalies (anomaly indicator)."
                f"\nVariance explained by first {df_pca.shape[1]} "
                f"PC's = {pca_explained_var:4.2f}%"
            )
        else:
            plot_title = (
                "Features with sum of model anomalies (anomaly indicator)\n"
                "and anomaly average over time"
            )
        df_reduced = df_reduced.assign(
            anomaly_indicator=df_with_anomaly_indicator.loc[:, anomaly_column]
        )
        datapoints_to_avg = int(np.floor(np.min([df_features.shape[0], 960]) / 2))
        hours_averaged_over = int(np.floor(datapoints_to_avg / 40))
        df_reduced[f"anomaly_{hours_averaged_over}h_average"] = (
            df_reduced["anomaly_indicator"].rolling(datapoints_to_avg).mean()
        )
        fig = df_reduced.plot(subplots=True)
        plt.suptitle(plot_title)
        return fig

    @staticmethod
    def plot_predictions(
        df_input: DataFrame,
        df_predictions: DataFrame,
        cols_to_plot: List[str] = None,
        lstm_model: bool = False,  # TODO should be removed, but kept it here for backward compatibility
        **kwargs,
    ):
        """
        Plots data and its autoencoder based reconstructions vs each other along
        with the mean squared error (mse) for visual comparison. Additional columns to be plotted can be added
        via keyword arguments (kwargs).

        :param df_input: the original data used as input to the autoencoder
        :type df_input: pandas.core.frame.DataFrame
        :param df_predictions: the autoencoder reconstructions of the original data in df_input
        :type df_predictions: pandas.core.frame.DataFrame
        :param cols_to_plot: the columns from df_input to plot, use "column_name_pred" for corresponding predictions
        :type cols_to_plot: List[str], default=None
        :param lstm_model: is the model a neural network of LSTM (recurrent time based network) type?
        :type lstm_model: bool, default=False
        """

        col_names = df_input.columns
        col_names_pred = col_names + "_pred"
        df_predictions.columns = col_names_pred
        df_all = pd.concat([df_input, df_predictions], 1)

        swapped_col_order = []
        for i in range(len(col_names)):
            swapped_col_order.append(col_names[i])
            swapped_col_order.append(col_names_pred[i])

        df_all = df_all[swapped_col_order]
        if cols_to_plot is None:
            N_cols_to_plot = len(col_names) if len(col_names) <= 5 else 5
            cols_to_plot = df_all.columns.values[0 : 2 * N_cols_to_plot]

        df_plots = df_all[cols_to_plot]

        graphs_in_same_plot = len(col_names) == len(col_names_pred)
        if graphs_in_same_plot:
            num_plots = int(df_plots.shape[1] / 2)
            fig, axes = plt.subplots(num_plots, 1, sharex=True)
            for axis, col in zip(np.arange(num_plots), np.arange(0, df_plots.shape[1], 2)):
                df_to_plot = df_plots.iloc[:, col : col + 2]
                df_to_plot.columns = ["Actual", "Predicted"]
                df_to_plot.index = pd.to_datetime(df_to_plot.index)
                df_to_plot.index = df_to_plot.index.map(lambda t: t.strftime("%d-%m-%Y"))
                df_to_plot.plot(ax=axes[axis], rot=15, legend=False)
                axes[axis].set_title(df_plots.columns[col], size=10)
                axes[axis].get_xaxis().get_label().set_visible(False)
            box = axes[axis].get_position()
            axes[axis].set_position(
                [box.x0, box.y0 + box.height * 0.1, box.width, box.height * 0.9]
            )
            plt.legend(
                bbox_to_anchor=(0.7, -0.01),
                loc="lower right",
                bbox_transform=fig.transFigure,
                ncol=2,
                fancybox=True,
                shadow=True,
            )
            plt.suptitle("Model predictions")
            fig.tight_layout()
        else:
            for key, value in kwargs.items():
                df_all[key] = kwargs[key]
                cols_to_plot.append(key)
            fig = df_all[cols_to_plot].plot(subplots=True)
        return fig

    @staticmethod
    def plot_error_distribution(
        mse: Union[Series, np.array], bins: int = 100, quantiles=None, **kwargs
    ):
        """
        Plots reconstruction error histogram with density estimate and
        vertical quantile bars

        :param mse: Reconstruction errors
        :type  mse: pandas.core.series.Series
        :param bins: the number of bins in the histogram
        :type  bins: int
        :param quantiles: the quantiles to display in the plot
        :type  quantiles: list[float]
        """
        if quantiles is None:
            quantiles = [0.95, 0.99, 0.995, 0.999]

        title = "Test set mean squared error (MSE)"
        fig = sns.histplot(mse, bins=bins, kde=True)
        for quantile in quantiles:
            plt.axvline(np.quantile(mse, quantile), color="red")

        if kwargs.get("component_name"):
            title = title + f" for {kwargs['component_name']}"
        if kwargs.get("training_period"):
            title = title + f" for {kwargs['training_period']}"

        plt.title(title)
        plt.xlabel("MSE")
        quantile_info_box = "\n".join(
            (
                f"99.9% percentile: {np.quantile(mse, 0.999):2.3f}",
                f"99.5% percentile: {np.quantile(mse, 0.995):2.3f}",
                f"99% percentile:    {np.quantile(mse, 0.99):2.3f}",
                f"95% percentile:    {np.quantile(mse, 0.95):2.3f}",
            )
        )
        fig.text(
            0.72,
            0.95,
            quantile_info_box,
            fontsize=11,
            verticalalignment="top",
            transform=fig.transAxes,
            bbox=dict(boxstyle="round", facecolor="wheat", alpha=0.5),
        )
        return fig

    @staticmethod
    def plot_scatter(
        x_train: DataFrame,
        y_hat: Union[DataFrame, np.array],
        y_train: Union[DataFrame, np.array],
        x_label: str = "",
        y_label: str = "",
        title: str = "",
    ):
        """
        Plot the trained regression model

        :param x_train: x_values to plot
        :type  x_train: array-like
        :param y_hat: predicted values from x_train
        :type  y_hat: array-like
        :param y_train: y_values
        :type  y_train: array-like
        :param x_label: name of label
        :type  x_label: str, default=""
        :param y_label: name of label
        :type  y_label: str, default=""
        :param title: plot title
        :type  title: str, default=""
        :return a matplotlib.pyplot figure object
        """
        fig = plt.figure()
        plt.plot(x_train, y_train, "o", label="Observed")
        plt.plot(x_train, y_hat, "o", label="Predicted")
        plt.xlabel(x_label)
        plt.ylabel(y_label)
        plt.title(title, loc="left", fontsize=18)
        plt.legend()
        return fig
